---
title: "Cluster Analysis"
author: "STA 3020A - Multivariate Modeling"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## What is clustering?

A form of exploratory data analysis (EDA) where observations are divided into meaningful groups that share common characteristics (features).

## Calculate & plot the distance between two players

You've obtained the coordinates relative to the center of the field for two players in a soccer match and would like to calculate the distance between them.

In this exercise you will plot the positions of the 2 players and manually calculate the distance between them by using the Euclidean distance formula.

## Instructions

-   Plot their positions from the two_players data frame using ggplot.

-   Extract the positions of the players into two data frames player1 and player2.

-   Calculate the distance between player1 and player2 by using the Euclidean distance formula

$\sqrt{(x_1-x_2)^2+(y_1-y_2)^2}$

```{r}
library(ggplot2)

two_players <- data.frame(
  x=c(5,15),
  y=c(4,10)
  ) 

# Plot the positions of the players
ggplot(two_players, aes(x = x, y = y), byrow=TRUE,nrow=2) + 
  geom_point() +
  # Assuming a 40x60 field
  lims(x = c(-30,30), y = c(-20, 20))
  
# Split the players data frame into two observations 
player1 <- two_players[1, ]
player2 <- two_players[2, ]

# Calculate and print their distance using the Euclidean Distance formula
player_distance <- sqrt( (player1$x - player2$x)^2 + (player1$y - player2$y)^2 )
player_distance
```

## Using the dist() function

Using the Euclidean formula manually may be practical for 2 observations but can get more complicated rather quickly when measuring the distance between many observations.

The $dist()$ function simplifies this process by calculating distances between our observations (rows) using their features (columns). In this case the observations are the player positions and the dimensions are their x and y coordinates.

Note: The default distance calculation for the $dist()$ function is Euclidean distance

## Instructions

-   Calculate the distance between two players using the dist() function for the data frame two_players.

-   Calculate the distance between three players for the data frame three_players.

```{r}
# Calculate the Distance Between two_players
dist_two_players <- dist(two_players)
dist_two_players

# Calculate the Distance Between three_players

three_players<- data.frame(
  x=c(5,15,0),
  y=c(4,10,20)
  )

dist_three_players <- dist(three_players)
dist_three_players
```

## Who are the closest players?

You are given the data frame containing the positions of 4 players on a soccer field.

Pre-load the four_players in your environment and is displayed below. Work in the R console to answer the following question:

-   Which two players are closest to one another?

```{r}
four_players <- data.frame(
  Player = c(1:4),
  x = c(5,15,0,-5),
  y = c(4,10,20,5)
  )
dist_four_players <- dist(four_players)
dist_four_players
```

## Importance of scaling

When a variable is on a larger scale than other variables in your data it may disproportionately influence the resulting distance calculated between your observations. Lets see this in action by observing a sample of data from the trees data set.

You will leverage the scale() function which by default centers & scales our column features.

Our variables are the following:

Girth - tree diameter in inches Height - tree height in inches

## Instructions

-   Calculate the distance matrix for the data frame three_trees and store it as dist_trees.

-   Create a new variable scaled_three_trees where the three_trees data is centered & scaled.

-   Calculate and print the distance matrix for scaled_three_trees and store this as dist_scaled_trees.

-   Output both dist_trees and dist_scaled_trees matrices and observe the change of which observations have the smallest distance between the two matrices (hint: they have changed).

```{r}
three_trees <- data.frame(
  Girth  = c(8.3,8.6,10.5),
  Height = c(840,780,864)
  )

# Calculate distance for three_trees 
dist_trees <- dist(three_trees)

# Scale three trees & calculate the distance  
scaled_three_trees <- scale(three_trees)
dist_scaled_trees <- dist(scaled_three_trees)

# Output the results of both Matrices
print('Without Scaling')
dist_trees

print('With Scaling')
dist_scaled_trees
```

## Calculating distance between categorial variables

In this exercise you will explore how to calculate binary (Jaccard) distances. In order to calculate distances we will first have to dummify our categories using the dummy.data.frame() from the library dummies

You will use a small collection of survey observations stored in the data frame job_survey with the following columns:

-   job_satisfaction Possible options: "Hi", "Mid", "Low"

-   is_happy Possible options: "Yes", "No

## instructions

-   Create a dummified data frame dummy_survey.

-   Generate a Jaccard distance matrix for the dummified survey data dist_survey using the dist() function using the parameter method = 'binary'.

-   Print the original data and the distance matrix. Note the observations with a distance of 0 in the original data (1, 2, and 3).

```{r}

library(dummy)
job_survey <- data.frame(
  job_satisfaction = c("Hi","Hi","Hi","Hi","Mid"),
  is_happy = c("No","No","No","Yes","No")
  )

# Dummify the Survey Data
dummy_survey <- dummy(job_survey)

# Calculate the Distance
dist_survey <- dist(dummy_survey, method = 'binary')

# Print the Original Data
job_survey

# Print the Distance Matrix
dist_survey

```

## Calculating linkage

Let us revisit the example with three players on a field. The distance matrix between these three players is shown below and is available as the variable dist_players.

From this we can tell that the first group that forms is between players 1 & 2, since they are the closest to one another with a Euclidean distance value of 11.

Now you want to apply the three linkage methods to determine what the distance of this group is to player 3.

## Instructions

Calculate the distance from player 3 to the group of players 1 & 2 using the following three linkage methods.

- Complete: the resulting distance is based on the maximum.
- Single: the resulting distance is based on the minimum.
- Average: the resulting distance is based on the average.

```{r}

dist_players<- dist(three_players)

# Extract the pair distances
distance_1_2 <- dist_players[1]
distance_1_3 <- dist_players[2]
distance_2_3 <- dist_players[3]

# Calculate the complete distance between group 1-2 and 3
complete <- max(c(distance_1_3, distance_2_3))
complete

# Calculate the single distance between group 1-2 and 3
single <- min(c(distance_1_3, distance_2_3))
single

# Calculate the average distance between group 1-2 and 3
average <- mean(c(distance_1_3, distance_2_3))
average
```
## Assign cluster membership

In this exercise you will leverage the $hclust())$ function to calculate the iterative linkage steps and you will use the $cutree()$ function to extract the cluster assignments for the desired number (k) of clusters.

You are given the positions of 12 players at the start of a 6v6 soccer match. This is stored in the lineup data frame.

You know that this match has two teams (k = 2), let's use the clustering methods you learned to assign which team each player belongs in based on their position.

Notes:

- The linkage method can be passed via the method parameter: hclust(distance_matrix, method = "complete")

- Remember that in soccer opposing teams start on their half of the field.

- Because these positions are measured using the same scale we do not need to re-scale our data.

## Instructions

- Calculate the Euclidean distance matrix dist_players among all twelve players.

- Perform the complete linkage calculation for hierarchical clustering using hclust and store this as hc_players.

- Build the cluster assignment vector clusters_k2 using cutree() with a k = 2.

- Append the cluster assignments as a column cluster to the lineup data frame and save the results to a new data frame called lineup_k2_complete.

```{r}
library(dplyr)
lineup <- data.frame(
  X  = c(-1,	-2,	8,	7,	-12,	-15,	-13,	15,	21,	12,	-25,	26),
  Y = c(1,	-3,	6,	-8,	8,	0,	-10,	16,	2,	-15,	1,	0)
  )

# Calculate the Distance
dist_players <- dist(lineup)

# Perform the hierarchical clustering using the complete linkage
hc_players <- hclust(dist_players, method = "complete")

# Calculate the assignment vector with a k of 2
clusters_k2 <- cutree(hc_players, k = 2)

# Create a new data frame storing these results
lineup_k2_complete <- mutate(lineup, cluster = clusters_k2)
```
## Exploring the clusters

Because clustering analysis is always in part qualitative, it is incredibly important to have the necessary tools to explore the results of the clustering.

In this exercise you will explore that data frame you created in the previous exercise lineup_k2_complete.

Reminder: The lineup_k2_complete data frame contains the x & y positions of 12 players at the start of a 6v6 soccer game to which you have added clustering assignments based on the following parameters:

- Distance: Euclidean
- Number of Clusters (k): 2
- Linkage Method: Complete

## Instructions

- Using count() from dplyr, count the number of players assigned to each cluster.
- Using ggplot(), plot the positions of the players and color them by cluster assignment.

```{r}

# Count the cluster assignments
count(lineup_k2_complete, cluster)

# Plot the positions of the players and color them using their cluster
ggplot(lineup_k2_complete, aes(x = X, y = Y, color = factor(cluster))) +
  geom_point()

```
## Comparing average, single & complete linkage

You are now ready to analyze the clustering results of the lineup dataset using the dendrogram plot. This will give you a new perspective on the effect the decision of the linkage method has on your resulting cluster analysis.

## Instructions

- Perform the linkage calculation for hierarchical clustering using the linkages: complete, single, and average.

- Plot the three dendrograms side by side and review the changes.

```{r}

# Prepare the Distance Matrix
dist_players <- dist(lineup)

# Generate hclust for complete, single & average linkage methods
hc_complete <- hclust(dist_players, method = "complete")
hc_single <- hclust(dist_players, method = "single")
hc_average <- hclust(dist_players, method = "average")

# Plot & Label the 3 Dendrograms Side-by-Side
# Hint: To see these Side-by-Side run the 4 lines together as one command
par(mfrow = c(1,3))
plot(hc_complete, main = 'Complete Linkage')
plot(hc_single, main = 'Single Linkage')
plot(hc_average, main = 'Average Linkage')


```

By comparing these three dendrograms, you can see how the choice of linkage method affects the hierarchical clustering result.

## Clusters based on height

In previous exercises, you have grouped your observations into clusters using a pre-defined number of clusters (k). In this exercise, you will leverage the visual representation of the dendrogram in order to group your observations into clusters using a maximum height (h), below which clusters form.

You will work the color_branches() function from the dendextend library in order to visually inspect the clusters that form at any height along the dendrogram.

The hc_players has been carried over from your previous work with the soccer line-up data.

## Instructions

- Create a dendrogram object dend_players from your hclust result using the function as.dendrogram().
- Plot the dendrogram.
- Using the color_branches() function create & plot a new dendrogram with clusters colored by a cut height of 20.
- Repeat the above step with a height of 40.

```{r}

library(dendextend)
dist_players <- dist(lineup, method = 'euclidean')
hc_players <- hclust(dist_players, method = "complete")

# Create a dendrogram object from the hclust variable
dend_players <- as.dendrogram(hc_players)

# Plot the dendrogram
plot(dend_players)

# Color branches by cluster formed from the cut at a height of 20 & plot
dend_20 <- color_branches(dend_players, h = 20)

# Plot the dendrogram with clusters colored below height 20
plot(dend_20)

# Color branches by cluster formed from the cut at a height of 40 & plot
dend_40 <- color_branches(dend_players, h = 40)

# Plot the dendrogram with clusters colored below height 40
plot(dend_40)



```

## Exploring the branches cut from the tree

The cutree() function you used in exercises 5 & 6 can also be used to cut a tree at a given height by using the h parameter. Take a moment to explore the clusters you have generated from the previous exercises based on the heights 20 & 40.

## Instructions

- Build the cluster assignment vector clusters_h20 using cutree() with a h = 20.

- Append the cluster assignments as a column cluster to the lineup data frame and save the results to a new data frame called lineup_h20_complete.

- Repeat the above two steps for a height of 40, generating the variables clusters_h40 and lineup_h40_complete.

- Use ggplot2 to create a scatter plot, colored by the cluster assignment for both heights.

```{r}

dist_players <- dist(lineup, method = 'euclidean')
hc_players <- hclust(dist_players, method = "complete")

# Calculate the assignment vector with a h of 20
clusters_h20 <- cutree(hc_players, h = 20)

# Create a new data frame storing these results
lineup_h20_complete <- mutate(lineup, cluster = clusters_h20)

# Calculate the assignment vector with a h of 40
clusters_h40 <- cutree(hc_players, h = 40)

# Create a new data frame storing these results
lineup_h40_complete <- mutate(lineup, cluster = clusters_h40)

# Plot the positions of the players and color them using their cluster for height = 20
ggplot(lineup_h20_complete, aes(x = X, y = Y, color = factor(cluster))) +
  geom_point()

# Plot the positions of the players and color them using their cluster for height = 40
ggplot(lineup_h40_complete, aes(x = X, y = Y, color = factor(cluster))) +
  geom_point()

```

## Segment wholesale customers

You're now ready to use hierarchical clustering to perform market segmentation (i.e. use consumer characteristics to group them into subgroups).

In this exercise you are provided with the amount spent by 45 different clients of a wholesale distributor for the food categories of Milk, Grocery & Frozen. This is stored in the data frame customers_spend. Assign these clients into meaningful clusters.

Note: For this exercise you can assume that because the data is all of the same type (amount spent) and you will not need to scale it.

## Instructions

- Calculate the Euclidean distance between the customers and store this in dist_customers.

- Run hierarchical clustering using complete linkage and store in hc_customers.

- Plot the dendrogram.

- Create a cluster assignment vector using a height of 15,000 and store it as clust_customers.

- Generate a new data frame segment_customers by appending the cluster assignment as the column cluster to the original customers_spend data frame.

```{r}
customers_spend <- read.csv("customers_spend.csv")

# Calculate Euclidean distance between customers
dist_customers <- dist(customers_spend)

# Generate a complete linkage analysis 
hc_customers <- hclust(dist_customers, method = "complete")

# Plot the dendrogram
plot(hc_customers)

# Create a cluster assignment vector at h = 15000
clust_customers <- cutree(hc_customers, h = 15000)

# Generate the segmented customers data frame
segment_customers <- mutate(customers_spend, cluster = clust_customers)

```

## Explore wholesale customer clusters

Continuing your work on the wholesale dataset you are now ready to analyze the characteristics of these clusters.

Since you are working with more than 2 dimensions it would be challenging to visualize a scatter plot of the clusters, instead you will rely on summary statistics to explore these clusters. In this exercise you will analyze the mean amount spent in each cluster for all three categories.

## Instructions

- Calculate the size of each cluster using count().
- Color & plot the dendrogram using the height of 15,000.
- Calculate the average spending for each category within each cluster using the summarise_all() function.

```{r}

dist_customers <- dist(customers_spend)
hc_customers <- hclust(dist_customers)
clust_customers <- cutree(hc_customers, h = 15000)
segment_customers <- mutate(customers_spend, cluster = clust_customers)

# Count the number of customers that fall into each cluster
count(segment_customers, cluster)

# Color the dendrogram based on the height cutoff
dend_customers <- as.dendrogram(hc_customers)
dend_colored <- color_branches(dend_customers, h = 15000)

# Plot the colored dendrogram
plot(dend_colored)

# Calculate the mean for each category
segment_customers %>% 
  group_by(cluster) %>% 
  summarise_all(list(mean))


```

## Interpreting the wholesale customer clusters

What observations can we make about our segments based on their average spending in each category?

- Customers in cluster 1 spent more money on Milk than any other cluster.

- Customers in cluster 3 spent more money on Grocery than any other cluster.

- Customers in cluster 4 spent more money on Frozen goods than any other cluster.

- The majority of customers fell into cluster 2 and did not show any excessive spending in any category.